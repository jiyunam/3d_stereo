{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "parallel_stereo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4ru-I0edknM",
        "outputId": "de54160f-c57b-4312-af98-3469de5b6977"
      },
      "source": [
        "!pip install opencv-contrib-python==3.4.0.12 # otherwise you'd get an error message saying this when you try to use SIFT\r\n",
        "                                   # This algorithm is patented and is excluded in this configuration; \r\n",
        "                                   # Set OPENCV_ENABLE_NONFREE CMake option and rebuild the library in \r\n",
        "                                   # function 'cv::xfeatures2d::SIFT::create'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opencv-contrib-python==3.4.0.12\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/ee/fb76784459b35c55740a0b20c7cfbd06752f9f8f96bf0bdcfafe2e8cf363/opencv_contrib_python-3.4.0.12-cp36-cp36m-manylinux1_x86_64.whl (30.5MB)\n",
            "\u001b[K     |████████████████████████████████| 30.5MB 163kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-contrib-python==3.4.0.12) (1.18.5)\n",
            "Installing collected packages: opencv-contrib-python\n",
            "  Found existing installation: opencv-contrib-python 4.1.2.30\n",
            "    Uninstalling opencv-contrib-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-contrib-python-4.1.2.30\n",
            "Successfully installed opencv-contrib-python-3.4.0.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSs_Obcye4Qk",
        "outputId": "c9bcf799-0dae-4c99-ba65-fc5494cd9fdb"
      },
      "source": [
        "import numpy as np\r\n",
        "from scipy import ndimage, signal\r\n",
        "from scipy.ndimage import gaussian_filter\r\n",
        "from copy import deepcopy\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "import random\r\n",
        "import math\r\n",
        "import os\r\n",
        "\r\n",
        "!pip install opencv-python\r\n",
        "import cv2\r\n",
        "\r\n",
        "import plotly.graph_objects as go\r\n",
        "\r\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68zHCR4Ahc7j"
      },
      "source": [
        "GAUSSIAN_BLUR_SIGMA=1"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UDjsbh-_e_7t"
      },
      "source": [
        "def compute_gaussian_subsample(image:np.ndarray, factor:int=2) -> np.ndarray:\r\n",
        "    temp_image = gaussian_filter(deepcopy(image), sigma=GAUSSIAN_BLUR_SIGMA)\r\n",
        "\r\n",
        "    len_x = temp_image.shape[0]\r\n",
        "    len_y = temp_image.shape[1]\r\n",
        "    half_len_x = int(len_x/2)\r\n",
        "    half_len_y = int(len_y/2)\r\n",
        "\r\n",
        "    # Subsample every other pixel\r\n",
        "    temp_image = deepcopy(temp_image[::factor,::factor])\r\n",
        "\r\n",
        "    # Gaussain blur\r\n",
        "    temp_image = gaussian_filter(temp_image, sigma=GAUSSIAN_BLUR_SIGMA)\r\n",
        "\r\n",
        "    return temp_image"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eWkMuSAf_gg"
      },
      "source": [
        "def get_images(path0, path1, factor=2):\r\n",
        "  img0 = cv2.imread(path0, cv2.IMREAD_GRAYSCALE)\r\n",
        "  img1 = cv2.imread(path1, cv2.IMREAD_GRAYSCALE)\r\n",
        "\r\n",
        "  # subsample because current imgs too big\r\n",
        "  img0 = compute_gaussian_subsample(img0,factor)\r\n",
        "  img1 = compute_gaussian_subsample(img1,factor)\r\n",
        "\r\n",
        "  #plt.subplot(1, 2, 1)\r\n",
        "  #plt.imshow(img0, cmap='gray')\r\n",
        "  #plt.subplot(1, 2, 2)\r\n",
        "  #plt.imshow(img1, cmap='gray')\r\n",
        "\r\n",
        "  return img0, img1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyWrOc6Ag3QQ"
      },
      "source": [
        "# def perform_SIFT(img1, img2):\r\n",
        "#   # temp naming everything SIFT\r\n",
        "#   # sift = cv2.xfeatures2d.SIFT_create()\r\n",
        "#   # kp1_SIFT, desc1_SIFT = sift.detectAndCompute(img1, None)\r\n",
        "#   # kp2_SIFT, desc2_SIFT = sift.detectAndCompute(img2, None)\r\n",
        "\r\n",
        "#   surf = cv2.xfeatures2d.SURF_create()\r\n",
        "#   kp1_SIFT, desc1_SIFT = surf.detectAndCompute(img1, None)\r\n",
        "#   kp2_SIFT, desc2_SIFT = surf.detectAndCompute(img2, None)\r\n",
        "\r\n",
        "#   # orb = cv2.ORB_create(nfeatures=1000)\r\n",
        "#   # kp1_SIFT, desc1_SIFT = orb.detectAndCompute(img1, None)\r\n",
        "#   # kp2_SIFT, desc2_SIFT = orb.detectAndCompute(img2, None)\r\n",
        "\r\n",
        "#   img1_SIFT = cv2.drawKeypoints(img1, kp1_SIFT, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS, color=(255,255,0))\r\n",
        "#   img2_SIFT = cv2.drawKeypoints(img2, kp1_SIFT, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS, color=(255,255,0))\r\n",
        "\r\n",
        "#   # #plt.figure()\r\n",
        "#   # fig, axs = plt.subplots(2,figsize=(10,10))\r\n",
        "#   # axs[0].imshow(img1_SIFT)\r\n",
        "#   # #plt.subplot(1, 2, 2)\r\n",
        "#   # axs[1].imshow(img2_SIFT)\r\n",
        "#   # plt.show()\r\n",
        "\r\n",
        "#   kp1 = kp1_SIFT\r\n",
        "#   kp2 = kp2_SIFT\r\n",
        "#   desc1 = desc1_SIFT\r\n",
        "#   desc2 = desc2_SIFT\r\n",
        "\r\n",
        "#   bf = cv2.BFMatcher()\r\n",
        "#   matches = bf.knnMatch(desc1, desc2, k=2) # k=2 means find the top two matchs for each query descriptor\r\n",
        "\r\n",
        "#   # Apply ratio test (as per David Lowe's SIFT paper: compare the best match with the 2nd best match_\r\n",
        "#   good_matches = []\r\n",
        "#   good_matches_without_list = []\r\n",
        "#   for m,n in matches:\r\n",
        "#       if m.distance < 0.75*n.distance: # only accept matchs that are considerably better than the 2nd best match\r\n",
        "#           good_matches.append([m])\r\n",
        "#           good_matches_without_list.append(m) # this is to simplify finding a homography later\r\n",
        "\r\n",
        "#   # plt.figure()\r\n",
        "#   # img3 = cv2.drawMatchesKnn(img1,kp1,img2,kp2,good_matches,\r\n",
        "#   #                         None,flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS, \r\n",
        "#   #                         matchColor=(0,255,0))\r\n",
        "#   # plt.figure(figsize = (10,10))\r\n",
        "#   # plt.imshow(img3), plt.show()\r\n",
        "\r\n",
        "#   src_pts = np.float32([ kp1[m.queryIdx].pt for m in good_matches_without_list ]).reshape(-1,1,2)\r\n",
        "#   dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good_matches_without_list ]).reshape(-1,1,2)\r\n",
        "\r\n",
        "#   return src_pts, dst_pts"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct1ByenfrofD"
      },
      "source": [
        "# Modified SIFT code from assignment\r\n",
        "def match_points(img1, img2, match_method='sift', ratio_param=0.75):\r\n",
        "  \r\n",
        "  if match_method == 'orb':\r\n",
        "    orb = cv2.ORB_create(nfeatures=1000)\r\n",
        "    kp1, desc1 = orb.detectAndCompute(img1, None)\r\n",
        "    kp2, desc2 = orb.detectAndCompute(img2, None)\r\n",
        "  elif match_method == 'surf':\r\n",
        "    surf = cv2.xfeatures2d.SURF_create()\r\n",
        "    kp1, desc1 = surf.detectAndCompute(img1, None)\r\n",
        "    kp2, desc2 = surf.detectAndCompute(img2, None)\r\n",
        "  else:\r\n",
        "    sift = cv2.xfeatures2d.SIFT_create()\r\n",
        "    kp1, desc1 = sift.detectAndCompute(img1, None)\r\n",
        "    kp2, desc2 = sift.detectAndCompute(img2, None)\r\n",
        "\r\n",
        "  bf = cv2.BFMatcher()\r\n",
        "  matches = bf.knnMatch(desc1, desc2, k=2) # k=2 means find the top two matchs for each query descriptor\r\n",
        "\r\n",
        "  # Apply ratio test (as per David Lowe's SIFT paper: compare the best match with the 2nd best match_\r\n",
        "  good_matches = []\r\n",
        "  good_matches_without_list = []\r\n",
        "  for m,n in matches:\r\n",
        "      if m.distance < ratio_param*n.distance: # only accept matchs that are considerably better than the 2nd best match\r\n",
        "          good_matches.append([m])\r\n",
        "          good_matches_without_list.append(m) # this is to simplify finding a homography later\r\n",
        "\r\n",
        "  src_pts = np.float32([ kp1[m.queryIdx].pt for m in good_matches_without_list ]).reshape(-1,1,2)\r\n",
        "  dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good_matches_without_list ]).reshape(-1,1,2)\r\n",
        "\r\n",
        "  return src_pts, dst_pts"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bmv0_OwyipEv"
      },
      "source": [
        "def extract_calibration_vals(file):\r\n",
        "  calib_vals = {}\r\n",
        "  with open(file) as f:\r\n",
        "    lines = f.readlines() # list containing lines of file\r\n",
        "    for line in lines:\r\n",
        "      line_split = line.split('=')\r\n",
        "      if line_split[0] == 'cam0' or line_split[0] == 'cam1':\r\n",
        "        matrix = line_split[1].strip('[]')\r\n",
        "        matrix = matrix.split(';')\r\n",
        "        matrix_vals = [[float(val.strip('[]')) for val in matrix_line.split()] for matrix_line in matrix]\r\n",
        "        calib_vals[line_split[0]] = np.array(matrix_vals)\r\n",
        "      else:\r\n",
        "        calib_vals[line_split[0]] = float(line_split[1].rstrip())\r\n",
        "  return calib_vals\r\n",
        "\r\n",
        "#extract_calibration_vals('calib.txt')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvdqRk7Cxg42"
      },
      "source": [
        "# remove points that are n stdev away from the mean\r\n",
        "def remove_outliers(world_coord, num_std=3):\r\n",
        "  mean_coord = np.array([np.mean(world_coord[:,0]), np.mean(world_coord[:,1]), np.mean(world_coord[:,2])])\r\n",
        "  stdev_coord = np.array([np.std(world_coord[:,0]), np.std(world_coord[:,1]), np.std(world_coord[:,2])])\r\n",
        "\r\n",
        "  world_coord = world_coord[(world_coord[:,0] > mean_coord[0] - num_std*stdev_coord[0]) & (world_coord[:,0] < mean_coord[0] + num_std*stdev_coord[0])]\r\n",
        "  world_coord = world_coord[(world_coord[:,1] > mean_coord[1] - num_std*stdev_coord[1]) & (world_coord[:,1] < mean_coord[1] + num_std*stdev_coord[1])]\r\n",
        "  world_coord = world_coord[(world_coord[:,2] > mean_coord[2] - num_std*stdev_coord[2]) & (world_coord[:,2] < mean_coord[2] + num_std*stdev_coord[2])]\r\n",
        "\r\n",
        "  return world_coord"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwgacOB4h2WK"
      },
      "source": [
        "# Get the 3D coordinates of the matches\r\n",
        "def get_world_coord(path0, path1, folder, match_method='sift', ratio_param=0.75):\r\n",
        "  factor = 2\r\n",
        "  path0 = os.path.join(folder, path0)\r\n",
        "  path1 = os.path.join(folder, path1)\r\n",
        "  img0, img1 = get_images(path0, path1, factor)\r\n",
        "  rgb0 = cv2.imread(path0)\r\n",
        "  # Extract matching points from the imgs\r\n",
        "  img0_pts, img1_pts = match_points(img0, img1, match_method, ratio_param)\r\n",
        "\r\n",
        "  # Acquire camera information\r\n",
        "  calib_vals = extract_calibration_vals(os.path.join(folder,'calib.txt'))\r\n",
        "  K0 = calib_vals['cam0']\r\n",
        "  K1 = calib_vals['cam1']\r\n",
        "  f = K0[0,0]\r\n",
        "  T = calib_vals['doffs']\r\n",
        "  px0 = K0[0,2]\r\n",
        "  px1 = K1[0,2]\r\n",
        "  py0 = K0[1,2]\r\n",
        "  py1 = K1[1,2]\r\n",
        "\r\n",
        "  img0_pts = np.array(img0_pts)\r\n",
        "  img1_pts = np.array(img1_pts)\r\n",
        "\r\n",
        "  img0_pts = img0_pts.reshape((img0_pts.shape[0],img0_pts.shape[2]))\r\n",
        "  img1_pts = img1_pts.reshape((img1_pts.shape[0],img1_pts.shape[2]))\r\n",
        "\r\n",
        "  # Calculate world coordinates per pixel\r\n",
        "  num_pts = len(img0_pts)\r\n",
        "  world_coord = np.zeros((num_pts,6))\r\n",
        "  for idx, pt in enumerate(img0_pts):\r\n",
        "    # Calculate depth using: z = fT/(xr-xl)\r\n",
        "    z = f*T/(np.absolute((pt[0])-(img1_pts[idx,0]))*factor)\r\n",
        "    world_coord[idx,2] = z\r\n",
        "\r\n",
        "    # x = fX/z + px, solve for X where X is world coordinate of x in the img\r\n",
        "    # X = (x-px)z/f\r\n",
        "    x0 = (pt[0]-px0)*factor*z/f\r\n",
        "    x1 = (img1_pts[idx,0]-px1)*factor*z/f\r\n",
        "    world_coord[idx,0] = -x0\r\n",
        "    #world_coord[idx,0] = -(x0+x1)/2\r\n",
        "    # do same for Y\r\n",
        "    y0 = (pt[1]-py0)*factor*z/f\r\n",
        "    y1 = (img1_pts[idx,1]-py1)*factor*z/f\r\n",
        "    world_coord[idx,1] = y0\r\n",
        "    #world_coord[idx,1] = (y0+y1)/2\r\n",
        "\r\n",
        "    # add colour\r\n",
        "    world_coord[idx,3:] = rgb0[int(pt[1])*factor,int(pt[0])*factor,:]\r\n",
        "\r\n",
        "  return world_coord\r\n",
        "\r\n",
        "# plot 3d point cloud of matches via plotly\r\n",
        "def plot_pointCloud(pc, path='plot.html'):\r\n",
        "    '''\r\n",
        "    plots the Nx6 point cloud pc in 3D\r\n",
        "    assumes (1,0,0), (0,1,0), (0,0,-1) as basis\r\n",
        "    '''\r\n",
        "    fig = go.Figure(data=[go.Scatter3d(\r\n",
        "        x=pc[:, 0],\r\n",
        "        y=pc[:, 1],\r\n",
        "        z=-pc[:, 2],\r\n",
        "        mode='markers',\r\n",
        "        marker=dict(\r\n",
        "            size=2,\r\n",
        "            color=pc[:, 3:][..., ::-1],\r\n",
        "            opacity=0.8\r\n",
        "        )\r\n",
        "    )])\r\n",
        "    fig.write_html(path)\r\n",
        "    #fig.show()\r\n",
        "\r\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go6PCSrSLmig"
      },
      "source": [
        "def test_imgs(path0, path1, folder='', match_method='sift'):\r\n",
        "  factor = 2\r\n",
        "  path0 = os.path.join(folder, path0)\r\n",
        "  path1 = os.path.join(folder, path1)\r\n",
        "  img0, img1 = get_images(path0, path1, factor)\r\n",
        "  rgb0 = cv2.imread(path0)\r\n",
        "\r\n",
        "  # Extract matching points from the imgs\r\n",
        "  img0_pts, img1_pts = match_points(img0, img1, match_method)\r\n",
        "\r\n",
        "  img0_pts = np.array(img0_pts)\r\n",
        "  img1_pts = np.array(img1_pts)\r\n",
        "  img0_pts = img0_pts.reshape((img0_pts.shape[0],img0_pts.shape[2]))\r\n",
        "  img1_pts = img1_pts.reshape((img1_pts.shape[0],img1_pts.shape[2]))\r\n",
        "\r\n",
        "  num_pts = len(img0_pts)\r\n",
        "  test_coord = np.zeros((num_pts,6))\r\n",
        "  for idx,pt in enumerate(img0_pts):\r\n",
        "    test_coord[idx,0] = -pt[0]*factor\r\n",
        "    test_coord[idx,1] = pt[1]*factor\r\n",
        "    test_coord[idx,2] = 5\r\n",
        "    test_coord[idx,3:] = rgb0[int(pt[1])*factor,int(pt[0])*factor,:]\r\n",
        "\r\n",
        "  plot_pointCloud(test_coord)\r\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiGMOdBiLl8D"
      },
      "source": [
        "def run(img0='im0.png', img1='im1.png', folder='', match_method='sift', ratio=0.75, outlier_bound=2, include_2d=True):\r\n",
        "  if include_2d:\r\n",
        "    # if you want to see the 2d point matches\r\n",
        "    test_imgs(img0,img1,folder,match_method)\r\n",
        "  world_coord = get_world_coord(img0, img1, folder, match_method, ratio)\r\n",
        "  world_coord = remove_outliers(world_coord, outlier_bound)\r\n",
        "  plot_pointCloud(world_coord)\r\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msAsov-7uzYG",
        "outputId": "e04817e1-202c-463b-e4db-5f8d40278da4"
      },
      "source": [
        "!unzip Imgs.zip"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  Imgs.zip\n",
            "   creating: Imgs/Bicycle/\n",
            "  inflating: Imgs/Bicycle/calib.txt  \n",
            "  inflating: Imgs/Bicycle/im0.png    \n",
            "  inflating: Imgs/Bicycle/im1.png    \n",
            "   creating: Imgs/Jadeplant/\n",
            "  inflating: Imgs/Jadeplant/calib.txt  \n",
            "  inflating: Imgs/Jadeplant/im0.png  \n",
            "  inflating: Imgs/Jadeplant/im1.png  \n",
            "   creating: Imgs/Mask/\n",
            "  inflating: Imgs/Mask/calib.txt     \n",
            "  inflating: Imgs/Mask/im0.png       \n",
            "  inflating: Imgs/Mask/im1.png       \n",
            "   creating: Imgs/Recycling/\n",
            "  inflating: Imgs/Recycling/calib.txt  \n",
            "  inflating: Imgs/Recycling/im0.png  \n",
            "  inflating: Imgs/Recycling/im1.png  \n",
            "   creating: Imgs/Storage/\n",
            "  inflating: Imgs/Storage/calib.txt  \n",
            "  inflating: Imgs/Storage/im0.png    \n",
            "  inflating: Imgs/Storage/im1.png    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbnBsRr0uT0N"
      },
      "source": [
        "def run_folder(pic):\r\n",
        "  pic_list = ['Bicycle', 'JadePlant', 'Mask', 'Recycling', 'Storage']\r\n",
        "  folder_name = os.path.join('Imgs', pic_list[pic])\r\n",
        "\r\n",
        "  run('im0.png', 'im1.png', folder=folder_name, match_method = 'surf', ratio=0.75, outlier_bound=2, include_2d=False)\r\n",
        "\r\n",
        "run_folder(3)"
      ],
      "execution_count": 14,
      "outputs": []
    }
  ]
}